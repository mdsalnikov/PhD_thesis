\chapter*{Conclusion}
\label{chap:conclusion}
\addcontentsline{toc}{chapter}{Conclusion}

This dissertation addressed the central challenge formulated in the introduction: how to fuse Large Language Models (LLMs) with Knowledge Graphs (KGs) to build question answering systems that are more accurate, reliable, and controllable. The work proposed two complementary methodologies and validated them through extensive experiments, ablations, and system demonstrations. In doing so, it focused not on repeating known results, but on highlighting what is new and practically useful: type-aware control of LLM generations and evidence-based reranking over KG subgraphs.

The main results of the dissertation are:

\begin{enumerate}
    \item \textbf{Answer Candidate Type (ACT) Selection.} A new method was proposed and validated that uses the LLM's ability to infer the expected semantic type of an answer and combines it with explicit type information from the KG (e.g., Wikidata P31). This type signal acts as a stable control to filter and rerank candidates. Hits@1 substantially improved across datasets and model sizes, e.g., on SQWD: \textbf{23.66} $\to$ \textbf{47.42} for T5-Large-SSM (fine-tuned), and in zero-shot: T5-11b-SSM-NQ \textbf{10.94} $\to$ \textbf{38.51}. Similar gains were observed on RuBQ and Mintaka. The ablation study confirmed that the full combination of scores (type, one-hop neighbors, Text-to-Text rank, question–property similarity) yields the best performance, while type alone is not sufficient. Importantly, ACT provides a resource-efficient path to close the gap between smaller and larger LLMs by adding controllability rather than parameters.
    
    \item \textbf{Controllable Fusion via subgraph reranking.} A general reranking framework was introduced that verifies LLM candidates against shortest-path subgraphs between question entities and answers in the KG. Multi-modal features were engineered (graph statistics such as PageRank, density, Katz centrality; text features; and Graph2Text sequences obtained by Deterministic linearization, T5-based, and GAP-based models). Across candidate sources (T5-Large-SSM, T5-XL-SSM, Mistral, Mixtral), reranking consistently improved quality over initial LLM rankings. For example, on Mintaka with T5-XL-SSM candidates, MPNet with Text+G2T features achieved \textbf{0.3923} Hits@1 versus \textbf{0.3042} without reranking; with Mixtral candidates, MPNet reached \textbf{0.5238--0.5270} Hits@1 versus \textbf{0.5173} without reranking. Feature-importance analyses demonstrated that \textbf{PageRank} is a strong and stable graph signal, while text-based features dominate overall. Graph2Text \textbf{T5} produced more faithful verbalizations than GAP in our setting, which explains its stronger downstream reranking performance.
    
    \item \textbf{ShortPathQA: a dataset for subgraph-based evaluation.} To enable standardized study of controllable fusion, the dissertation introduced ShortPathQA—the first QA resource that releases pre-computed shortest-path subgraphs linking question entities and candidate answers. The dataset contains \textbf{12,526} questions and \textbf{143,061} question–candidate pairs with subgraphs (\textbf{435,187} nodes, \textbf{498,570} edges; \textbf{32,226} unique nodes). A manually curated test set complements an automatic split and targets more complex reasoning. Baselines show that models benefit more from graphs on the manual set, indicating that richer subgraphs are particularly helpful for multi-step questions.
    
    \item \textbf{Systems and tooling.} The work delivered production-style components: a baseline Seq2Seq pipeline, ACT Selection, and a web tool for subgraph visualization. All components are exposed as REST APIs (FastAPI) and demonstrate technological readiness. They make the proposed methods reproducible and usable for the community.
    
    \item \textbf{Empirical principles for controllable KG–LLM fusion.} Two consistent observations guide future designs: (i) LLMs often infer the correct \emph{type} even when the top-1 answer is wrong, making type a robust control signal for KGQA; (ii) explicit \emph{path evidence} from KGs reduces hallucinations and improves interpretability when used to rerank candidates. Together, these principles explain why ACT and subgraph reranking are effective and complementary.
\end{enumerate}

\noindent\textbf{Limitations and future extensions.} While the proposed methods improved reliability and control, several limitations remain. ACT relies on the availability and quality of type schema and entity linking, and subgraph reranking currently focuses on shortest paths and one-hop settings in candidate sourcing. Zero-shot prompting of LLMs with subgraphs was not always effective; better interfaces for models to consume structured evidence are needed. Finally, scaling to larger multilingual settings and domain-specific KGs requires additional engineering.

The most promising directions for further development of the research are:
\begin{itemize}
    \item \textbf{From shortest paths to richer subgraphs and multi-hop reasoning:} extend beyond single shortest paths to bounded-depth induced subgraphs and relation patterns; early results on the manual set suggest larger gains on compositional questions.
    \item \textbf{Stronger model interfaces for KG evidence:} develop structured prompting, tool-use, or lightweight adapters so LLMs can reliably consume subgraphs without performance drops, complementing the demonstrated gains from supervised finetuning.
    \item \textbf{Dataset growth and analysis tooling:} expand ShortPathQA with more complex questions, richer annotations, and standardized Graph2Text outputs to facilitate detailed error analysis and benchmarking.
\end{itemize}

\noindent In conclusion, the dissertation provides a clear recipe for making LLM-based QA more factual and controllable: use \emph{type} to constrain and use \emph{subgraph evidence} to verify. Together with public systems and a new dataset, these contributions form a practical foundation for future research and applications.

