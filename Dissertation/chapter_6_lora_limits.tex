\chapter{On the Limits of Internalizing Knowledge: Insights from LoRA}
\label{chap:lora_limits}

% Comment: This chapter incorporates the findings from "How Much Knowledge Can You 
% Pack...", positioning it as an exploration complementary to the main KG fusion 
% theme.

% 6.1 Knowledge Integration Strategies: External vs. Internal
\section{Knowledge Integration Strategies: External vs. Internal}
\label{sec:lora_external_vs_internal}
% Comment: Revisit the idea of different ways to provide knowledge to LLMs. Contrast 
% the *external* approach (using KGs, as explored in Chapters 3-5) with *internal* 
% approaches like fine-tuning or parameter modification using methods like LoRA.


% 6.2 Investigating Knowledge Capacity in LoRA Adapters
\section{Investigating Knowledge Capacity in LoRA Adapters}
\label{sec:lora_capacity_investigation}
% Comment: Describe the study from "How Much Knowledge Can You Pack...". Explain the 
% methodology for "packing" knowledge into LoRA adapters and for measuring the 
% trade-off between acquired knowledge and the preservation of the base LLM's general 
% abilities.


% 6.3 Findings and Implications for KG-LLM Approaches
\section{Findings and Implications for KG-LLM Approaches}
\label{sec:lora_implications}
% Comment: Present the key results regarding the capacity limits of LoRA for storing 
% knowledge. Discuss the implications: Do these findings suggest inherent limitations 
% to solely relying on internalizing knowledge within LLM parameters, especially for 
% vast, dynamic factual information? Argue how these results might strengthen the case 
% for hybrid approaches that leverage external, structured knowledge sources like KGs 
% for robust factuality. 

\chapter{System Demonstrations and Implementation}
\label{chap:system_demos}

\section{Introduction}
\label{sec:demo:intro}
This chapter showcases the practical implementations of the methods discussed in earlier chapters. Moving from theoretical foundations to real-world applications, we present system demonstrations that illustrate how the fusion of Large Language Models (LLMs) and Knowledge Graphs (KGs) can be deployed to address factoid question answering tasks. These implementations serve not only as proof-of-concept for our methodological contributions but also as usable tools for researchers and potential end-users in the field.

\section{System for Answering Simple Questions}
\label{sec:demo:simple_qa}
% TODO: Describe the demo system from the ACL Demo paper.
% TODO: Explain its architecture and functionality.
% TODO: Connect it to the core methods discussed earlier.
% TODO: Mention your role in its development.

\section{Web Application for Knowledge Graph Path Visualization}
\label{sec:demo:kg_path_viz}
% TODO: Describe the web application for visualizing knowledge graph paths.
% TODO: Explain how it helps users understand the paths connecting entities.
% TODO: Discuss implementation details and technologies used.

\section{Reranking Demonstration Tool}
\label{sec:demo:reranking}
% TODO: Describe the demonstration tool for reranking answers.
% TODO: Explain how it incorporates the controllable fusion techniques.
% TODO: Showcase example usage and interface design.

\section{Integration with External Systems}
\label{sec:demo:integration}
% TODO: Discuss how these components can be integrated with other systems.
% TODO: Address API design, modularity, and extensibility.

\section{Chapter Summary}
\label{sec:demo:summary}
% TODO: Summarize the key takeaways from the demonstrations. 